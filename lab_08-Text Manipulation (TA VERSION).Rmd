---
title: 'Statistical Computing: Text Manipulation (TA VERSION)'
author: "TA: Daniel Zhu"
date: "Week of Tuesday October 24, 2023"
output: pdf_document
---

```{r, include=FALSE}
# A hook to wrap output based on a linewidth chunk option
# From https://github.com/yihui/knitr-examples/blob/master/077-wrap-output.Rmd
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = knitr:::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})
opts_chunk$set(cache=TRUE, autodep=TRUE, cache.comments=TRUE, linewidth=79)
```

**This week's agenda**: basic string manipulations; practice reading in and summarizing real text data (Shakespeare); practice with iteration; just a little bit of regular expressions.

Q1. Some string basics
===

- **1a.** Define two strings variables, equal to "Statistical Computing" and 'Statistical Computing', and check whether they are equal. What do you conclude about the use of double versus single quotation marks for creating strings in R? Give an example that shows why might we prefer to use double quotation marks as the standard (think of apostrophes).

```{r q1a}
random1 <- "Statistical Computing"
weatherIsNiceToday <- 'Statistical Computing'
class(random1)
class(weatherIsNiceToday)
```
**Answer: Both are characters, enabling us to employ either double or single quotation marks to construct strings in R. Opting for double quotation marks when crafting this string, "I didn't see it," transforms it into "I didn't see it." However, should single quotation marks be chosen, it transforms into 'I didn't see it,' resulting in an error.**

- **1b.** The functions `tolower()` and `toupper()` do as you'd expect: they convert strings to all lower case characters, and all upper case characters, respectively. Apply them to the strings below, as directed by the comments, to observe their behavior.

```{r}
"I'M NOT ANGRY I SWEAR"         # Convert to lower case
"Mom, I don't want my veggies"  # Convert to upper case
"Hulk, sMasH"                   # Convert to upper case
"R2-D2 is in prime condition, a real bargain!" # Convert to lower case
```

```{r q1b}
tolower("I'M NOT ANGRY I SWEAR")
toupper("Mom, I don't want my veggies")
toupper("Hulk, sMasH")
tolower("R2-D2 is in prime condition, a real bargain!")
```

- **1c.** Consider the string vector `presidents` of length 5 below, containing the last names of past US presidents. Define a string vector `first.letters` to contain the first letters of each of these 5 last names. Hint: use `substr()`, and take advantage of vectorization; this should only require one line of code. Define `first.letters.scrambled` to be the output of `sample(first.letters)` (the `sample()` function can be used to perform random permutations, we'll learn more about it later in the course). Lastly, reset the first letter of each last name stored in `presidents` according to the scrambled letters in `first.letters.scrambled`. Hint: use `substr()` again, and take advantage of vectorization; this should only take one line of code. Display these new last names.

```{r}
presidents = c("Taylor", "Fillmore", "Pierce", "Buchanan", "Lincoln")
```

```{r q1c}
presidents = c("Taylor", "Fillmore", "Pierce", "Buchanan", "Lincoln")
first.letters = substr(presidents, 1, 1)
first.letters.scrambled = sample(first.letters)
presidents = paste(first.letters.scrambled, substr(presidents, 1, 
                                                   nchar(presidents)), sep = "")
presidents
first.letters
first.letters.scrambled
```

- **1d.** Now consider the string `phrase` defined below. Using `substr()`, replace the first four characters in `phrase` by "Provide". Print `phrase` to the console, and describe the behavior you are observing. Using `substr()` again, replace the last five characters in `phrase` by "kit" (don't use the length of `phrase` as magic constant in the call to `substr()`, instead, compute the length using `nchar()`). Print `phrase` to the console, and describe the behavior you are observing.

```{r}
phrase = "Give me a break"
```

```{r q1d}
substr(phrase, 1, 4) <- "Provide"
phrase

substr(phrase, nchar(phrase) - 4, nchar(phrase)) <- "kit"
phrase
```
**Answer: I can replace a maximum of 4 characters with up to 4 characters. So, "Provide" became "Prov" because it replaced 4 characters. If I replace 5 characters with a shorter string, it fills in the remaining characters with the original content. For example, "kit" is 3 characters, and replacing 5 characters resulted in "kit" plus the last 2 characters from the original string.**

- **1e.** Consider the string `ingredients` defined below. Using `strsplit()`, split this string up into a string vector of length 5, with elements "chickpeas", "tahini", "olive oil", "garlic", and "salt." Using `paste()`, combine this string vector into a single string "chickpeas + tahini + olive oil + garlic + salt". Then produce a final string of the same format, but where the ingredients are sorted in alphabetical (increasing) order.

```{r}
ingredients = "chickpeas, tahini, olive oil, garlic, salt"
```

```{r q1e}
split.ing <- strsplit(ingredients, split = ", ")[[1]]
ingredient_vector = unlist(strsplit(ingredients, ", "))
sorted_ingredients = paste(sort(ingredient_vector), collapse = " + ")
split.ing
sorted_ingredients
```

Shakespeare's complete works
===

[Project Gutenberg](http://www.gutenberg.org) offers over 50,000 free online books, especially old books (classic literature), for which copyright has expired. We're going to look at the complete works of [William Shakespeare](https://en.wikipedia.org/wiki/William_Shakespeare), taken from the Project Gutenberg website. 

To avoid hitting the Project Gutenberg server over and over again, we've grabbed a text file from them that contains the complete works of William Shakespeare and put it on our course website. Visit  https://www.stat.cmu.edu/~ftownes/teaching/36350/F23/data/shakespeare.txt in your web browser and just skim through this text file a little bit to get a sense of what it contains (a whole lot!). 

Q2. Reading in text, basic exploratory tasks
===

- **2a.** Read in the Shakespeare data linked above into your R session with `readLines()`. Make sure you are reading the data file directly from the web (rather than locally, from a downloaded file on your computer). Call the result `shakespeare.lines`. This should be a vector of strings, each element representing a "line" of text. Print the first 10 lines. How many lines are there? How many characters in the longest line? What is the average number of characters per line? How many lines are there with zero characters (empty lines)? Hint: each of these queries should only require one line of code; for the last one, use an on-the-fly Boolean comparison and `sum()`.

```{r q2a}
shakespeare.lines <- readLines("https://www.stat.cmu.edu/~ftownes/teaching/36350/F23/data/shakespeare.txt")
shakespeare.lines[1:10]

length(shakespeare.lines)
max(nchar(shakespeare.lines))
sum(nchar(shakespeare.lines))/length(shakespeare.lines)
length(shakespeare.lines[nchar(shakespeare.lines) == 0])
```
**Answer:  There are 147,838 lines. The longest line has 78 characters. The average number of characters per line is about 37.5. There are 17744 lines with zero characters. However the first time I got 85 for longest line characters and can not reproduce it again**

- **2b.** Remove all empty lines from `shakespeare.lines` (i.e., lines with zero characters). Check that that the new length of `shakespeare.lines` makes sense to you.

```{r q2b}
shakespeare.lines <- shakespeare.lines[nchar(shakespeare.lines) != 0]
length(shakespeare.lines)
```

- **2c.** Collapse the lines in `shakespeare.lines` into one big string, separating each line by a space in doing so, using `paste()`. Call the resulting string `shakespeare.all`. How many characters does this string have? How does this compare to the sum of characters in `shakespeare.lines`, and does this make sense to you?

```{r q2c}
shakespeare.all <- paste(shakespeare.lines, collapse = " ")
nchar(shakespeare.all)
sum(nchar(shakespeare.lines))
```
**Answer: We got 5,690,990 characters which is more than the sum of characters in shakespare.lines and it makes sense as shakespeare.all has space between every line and each space adds a character.**

- **2d.** Split up `shakespeare.all` into words, using `strsplit()` with `split=" "`. Call the resulting string vector (note: here we are asking you for a vector, not a list) `shakespeare.words`. How long is this vector, i.e., how many words are there? Using the `unique()` function, compute and store the unique words as `shakespeare.words.unique`. How many unique words are there?  

```{r q2d}
shakespeare.words <- strsplit(shakespeare.all, split = " ")[[1]]
shakespeare.words.unique <- unique(shakespeare.words)
length(shakespeare.words)
length(shakespeare.words.unique)
```
**Answer: There are 1,370,374 words. There are 76,171 unique words.**

- **2e.** Plot a histogram of the number of characters of the words in `shakespeare.words.unique`. You will have to set a large value of the `breaks` argument (say, `breaks=50`) in order to see in more detail what is going on. What does the bulk of this distribution look like to you? Why is the x-axis on the histogram extended so far to the right (what does this tell you about the right tail of the distribution)?

```{r q2e}
hist(nchar(shakespeare.words.unique), breaks = 50)

order(nchar(shakespeare.words.unique), decreasing = TRUE)[1:5]
shakespeare.words.unique[order(nchar(shakespeare.words.unique), 
                                   decreasing = TRUE)[01:5]]
```
**Answer: The majority of this data distribution exhibits a bell curve shape with a peak centered around 7 characters. Although there are several exceptional data points, the majority of values fall within the range of 0 to 17 characters, forming a pattern reminiscent of a normal distribution. The extension of the x-axis to the right is a result of the presence of words with more than 20 characters. This indicates that the distribution's right tail is relatively lighter and stretches all the way to 60 characters, implying a slight rightward skew in the distribution.**

- **2f.** Reminder: the `sort()` function sorts a given vector into increasing order; its close friend, the `order()` function, returns the indices that put the vector into increasing order. Both functions can take `decreasing=TRUE` as an argument, to sort/find indices according to decreasing order. See the code below for an example.
    ```{r}
    set.seed(0)
    (x = round(runif(5, -1, 1), 2))
    sort(x, decreasing=TRUE)
    order(x, decreasing=TRUE)
    ```
    Using the `order()` function, find the indices that correspond to the top 5 longest words in `shakespeare.words.unique`. Then, print the top 5 longest words themselves. Do you recognize any of these as actual words? **Challenge**: try to pronounce the fourth longest word! What does it mean?
    
```{r q2f}
order(nchar(shakespeare.words.unique), decreasing = TRUE)[1:5]
shakespeare.words.unique[order(nchar(shakespeare.words.unique), decreasing = TRUE)[01:5]]
```
**Answer: As a pseudo-linguistics expert I can say it has something to do with Honor, Google confirms that it is in fact so as it is "the state of being able to achieve honors"**

Q3. Computing word counts
===

- **3a.** Using `table()`, compute counts for the words in `shakespeare.words`, and save the result as `shakespeare.wordtab`. How long is `shakespeare.wordtab`, and is this equal to the number of unique words (as computed above)? Using named indexing, answer: how many times does the word "thy" appear? The word "rumour"? The word "gloomy"? The word "assassination"?

```{r q3a}
shakespeare.wordtab <- table(shakespeare.words)
length(shakespeare.wordtab)
shakespeare.wordtab["thy"]
shakespeare.wordtab["rumour"]
shakespeare.wordtab["gloomy"]
shakespeare.wordtab["assassination"]
```
**Answer: Shakespeare.wordtab is 76171 long and it is equal to the number of unique words. Thy comes up 3912 times, rumour appears 7 times, gloomy appears 3 times, and assassination appears once.**

- **3b.** How many words did Shakespeare use just once? Twice? At least 10 times? More than 100 times? 

```{r q3b}
length(which(shakespeare.wordtab == 1))
length(which(shakespeare.wordtab == 2))
length(which(shakespeare.wordtab >= 10))
length(which(shakespeare.wordtab > 100))
```
**Answer: The good boss man used 41,842 words just once, used 10,756 words twice, used 8,187 words at least 10 times, and used 975 words more than a 100 times.**

- **3c.** Sort `shakespeare.wordtab` so that its entries (counts) are in decreasing order, and save the result as `shakespeare.wordtab.sorted`. Print the 25 most commonly used words, along with their counts. What is the most common word? Second and third most common words?

```{r q3c}
shakespeare.wordtab.sorted <- sort(shakespeare.wordtab, decreasing = TRUE)
head(shakespeare.wordtab.sorted,25)
```
**Answer: The, I, and And are the top three most common words**

- **3d.** What you should have seen in the last question is that the most common word is the empty string "". This is just an artifact of splitting `shakespeare.all` by spaces, using `strsplit()`. Redefine `shakespeare.words` so that all empty strings are deleted from this vector. Then recompute `shakespeare.wordtab` and `shakespeare.wordtab.sorted`. Check that you have done this right by printing out the new 25 most commonly used words, and verifying (just visually) that is overlaps with your solution to the last question.

```{r q3d}
shakespeare.words <- shakespeare.words[which(shakespeare.words != "")]
shakespeare.wordtab <- table(shakespeare.words)

shakespeare.wordtab.sorted <- sort(shakespeare.wordtab, decreasing = TRUE)
head(shakespeare.wordtab.sorted,25)
```
**Answer: Yes it overlaps**

- **3e.** As done at the end of the lecture notes, produce a plot of the word counts (y-axis) versus the ranks (x-axis) in `shakespeare.wordtab.sorted`. Set `xlim=c(1,1000)` as an argument to `plot()`; this restricts the plotting window to just the first 1000 ranks, which is helpful here to see the trend more clearly. Do you see **Zipf's law** in action, i.e., does it appear that $\mathrm{Frequency} \approx C(1/\mathrm{Rank})^a$ (for some $C,a$)? **Challenge**: either programmatically, or manually, determine reasonably-well-fitting values of $C,a$ for the Shakespeare data set; then draw the curve $y=C(1/x)^a$ on top of your plot as a red line to show how well it fits.

```{r q3e}
nw = length(shakespeare.wordtab.sorted)
x <- 1:nw
frequencies <- as.numeric(shakespeare.wordtab.sorted)

fit_zipf <- lm(log(frequencies) ~ log(1/x))
C <- exp(coef(fit_zipf)[1])
a <- -coef(fit_zipf)[2]


zipf_curve <- C * (1/x)^a


plot(x, frequencies, type = "l", xlab = "x", 
     ylab = "Frequency", xlim = c(1, 1000))
lines(x, zipf_curve, col = "red")
```
**Yup we do see Zipf's Law because rank and frequency are inversely related. Not sure why my red line isn't displaying**

Q4. A tiny bit of regular expressions
===

- **4a.** There are a couple of issues with the way we've built our words in `shakespeare.words`. The first is that capitalization matters; from Q3c, you should have seen that "and" and "And" are counted as separate words. The second is that many words contain punctuation marks (and so, aren't really words in the first place); to see this, retrieve the count corresponding to "and," in your word table `shakespeare.wordtab`.

  The fix for the first issue is to convert `shakespeare.all` to all lower case characters. Hint: recall `tolower()` from Q1b. The fix for the second issue is to use the argument `split="[[:space:]]|[[:punct:]]"` in the call to `strsplit()`, when defining the words. In words, this means: *split on spaces or on punctuation marks* (more precisely, it uses what we call a **regular expression** for the `split` argument). Carry out both of these fixes to define new words `shakespeare.words.new`. Then, delete all empty strings from this vector, and compute word table from it, called `shakespeare.wordtab.new`. 
```{r q4a}
shakespeare.wordtab["and"]
shakespeare.words.new <- tolower(unlist(strsplit(shakespeare.all, 
                                        split = "[[:space:]]|[[:punct:]]")))
shakespeare.words.new <- shakespeare.words.new[shakespeare.words.new != ""]
shakespeare.wordtab.new <- table(shakespeare.words.new)
```

- **4b.** Compare the length of `shakespeare.words.new` to that of `shakespeare.words`; also compare the length of `shakespeare.wordtab.new` to that of `shakespeare.wordtab`. Explain what you are observing.

```{r q4b}
length(shakespeare.words.new)
length(shakespeare.words)
length(shakespeare.wordtab.new)
length(shakespeare.wordtab)
```
**Answer: The length of shakespeare.words.new is bigger than the length of shakespeare.words. The length of shakespeare.wordtab.new is much, much smaller than the length of shakespeare.wordtab. This likely means there are many more unique words/characters/symbols in shakespeare.words, than shakespeare.words.new. We would need to restructure and clean the data** 

- **4c.** Compute the unique words in `shakespeare.words.new`, calling the result `shakespeare.words.new.unique`. Then repeat the queries in Q2e and Q2f on `shakespeare.words.new.unique`. Comment on the histogram---is it different in any way than before? How about the top 5 longest words? 

```{r q4c}
shakespeare.words.new.unique <- unique(shakespeare.words.new)
hist(nchar(shakespeare.words.new.unique), breaks = 50)
order(nchar(shakespeare.words.new.unique), decreasing = TRUE)[1:5]
shakespeare.words.new.unique[order(nchar(shakespeare.words.new.unique), 
                                   decreasing = TRUE)[01:5]]
```
**Answer: Range is interesting as the x axis stops at 25 instead of 60 and the characters look like they have a normal distrubution bell curve around 7 and the top 5 longest words are the same still**

- **4d.** Sort `shakespeare.wordtab.new` so that its entries (counts) are in decreasing order, and save the result as `shakespeare.wordtab.sorted.new`. Print out the 25 most common words and their counts, and compare them (informally) to what you saw in Q3d. Also, produce a plot of the new word counts, as you did in Q3e. Does Zipf's law look like it still holds?

```{r q4d}
shakespeare.wordtab.sorted.new = sort(shakespeare.wordtab.new, 
                                       decreasing = TRUE)
nw = length(shakespeare.wordtab.sorted.new)
plot(1:nw, as.numeric(shakespeare.wordtab.sorted.new), type = "l",
     xlab="Rank", ylab="Frequency", xlim = c(1,1000))
head(shakespeare.wordtab.sorted.new, 25)
```
**Zipf's still holds but the word counts are different for the items on top of the list**

Q5. Where are Shakespeare's plays, in this massive text?
===

- **5a.** Let's go back to `shakespeare.lines`. Take a look at lines 19 through 23 of this vector: you should see a bunch of spaces preceding the text in lines 21, 22, and 23. Redefine `shakespeare.lines` by setting it equal to the output of calling the function `trimws()` on `shakespeare.lines`. Print out lines 19 through 23 again, and describe what's happened.

```{r q5a}
shakespeare.lines[19:23]
shakespeare.lines <- trimws(shakespeare.lines)
shakespeare.lines[19:23]
```
**Answer: Extra spacing is deleted so we get nicer packaging of the displayed outputs**

- **5b.** Visit https://www.stat.cmu.edu/~ftownes/teaching/36350/F23/data/shakespeare.txt in your web browser and just skim through this text file. Near the top you'll see a table of contents. Note that "THE SONNETS" is the first play, and "VENUS AND ADONIS" is the last. Using `which()`, find the indices of the lines in `shakespeare.lines` that equal "THE SONNETS", report the index of the *first* such occurence, and store it as `toc.start`. Similarly, find the indices of the lines in `shakespeare.lines` that equal "VENUS AND ADONIS", report the index of the *first* such occurence, and store it as `toc.end`.

```{r q5b}
toc.start <- which(shakespeare.lines == "THE SONNETS")[1]
toc.end <- which(shakespeare.lines == "VENUS AND ADONIS")[1]
toc.start
toc.end
```
**Answer: the 22nd index was where the frist occurence of The Sonnets and 65 the first for Venus and Adonis**

- **5c.** Define `n = toc.end - toc.start + 1`, and create an empty string vector of length `n` called `titles`. Using a `for()` loop, populate `titles` with the titles of Shakespeare's plays as ordered in the table of contents list, with the first being "THE SONNETS", and the last being "VENUS AND ADONIS". Print out the resulting `titles` vector to the console. Hint: if you define the counter variable `i` in your `for()` loop to run between 1 and `n`, then you will have to index `shakespeare.lines` carefully to extract the correct titles. Think about the following. When `i=1`, you want to extract the title of the first play in `shakespeare.lines`, which is located at index `toc.start`. When `i=2`, you want to extract the title of the second play, which is located at index `toc.start + 1`. And so on.

```{r q5c}
n = toc.end - toc.start + 1
titles = character(n)
for (x in 1:n) {
  titles[x] = shakespeare.lines[toc.start + x - 1]
}

titles
```

- **5d.** Use a `for()` loop to find out, for each play, the index of the line in `shakespeare.lines` at which this play begins. It turns out that the *second* occurence of "THE SONNETS" in `shakespeare.lines` is where this play actually begins (this first ocurrence is in the table of contents), and so on, for each play title. Use your `for()` loop to fill out an integer vector called `titles.start`, containing the indices at which each of Shakespeare's plays begins in `shakespeare.lines`. Print the resulting vector `titles.start` to the console.

```{r q5d}
titles.start = integer(n)
for (x in 1:n){
  titles.start[x] = which(shakespeare.lines == titles[x])[2]
}
titles.start
```

- **5e.** Define `titles.end` to be an integer vector of the same length as `titles.start`, whose first element is the second element in `titles.start` minus 1, whose second element is the third element in `titles.start` minus 1, and so on. What this means: we are considering the line before the second play begins to be the last line of the first play, and so on. Define the last element in `titles.end` to be the length of `shakespeare.lines`. You can solve this question either with a `for()` loop, or with proper indexing and vectorization. **Challenge**: it's not really correct to set the last element in `titles.end` to be length of `shakespeare.lines`, because there is a footer at the end of the Shakespeare data file. By looking at the data file visually in your web browser, come up with a way to programmatically determine the index of the last line of the last play, and implement it.

```{r q5e}
titles.end = integer(n)
for (x in 1:n){
  if (x == n){titles.end[x] = length(shakespeare.lines)}
  else {titles.end[x] = titles.start[x + 1] - 1}
}

titles.end
```

- **5f.** In Q5d, you should have seen that the starting index of Shakespeare's 38th play "THE TWO NOBLE KINSMEN" was computed to be `NA`, in the vector `titles.start`. Why? If you run `which(shakespeare.lines == "THE TWO NOBLE KINSMEN")` in your console, you will see that there is only one occurence of "THE TWO NOBLE KINSMEN" in `shakespeare.lines`, and this occurs in the table of contents. So there was no second occurence, hence the resulting `NA` value.

  But now take a look at line 118,463 in `shakespeare.lines`: you will see that it is "THE TWO NOBLE KINSMEN:", so this is really where the second play starts, but because of colon ":" at the end of the string, this doesn't exactly match the title "THE TWO NOBLE KINSMEN", as we were looking for. The advantage of using the `grep()` function, versus checking for exact equality of strings, is that `grep()` allows us to match substrings. Specifically, `grep()` returns the indices of the strings in a vector for which a substring match occurs, e.g.,
```{r}
  grep(pattern="cat", 
       x=c("cat", "canned goods", "batman", "catastrophe", "tomcat"))
```
    
  so we can see that in this example, `grep()` was able to find substring matches to "cat" in the first, fourth, and fifth strings in the argument `x`. Redefine `titles.start` by repeating the logic in your solution to Q5d, but replacing the `which()` command in the body of your `for()` loop with an appropriate call to `grep()`. Also, redefine `titles.end` by repeating the logic in your solution to Q5e. Print out the new vectors `titles.start` and `titles.end` to the console---they should be free of `NA` values.
    
```{r q5f}
for (x in 1:n){
  titles.start[x] = grep(pattern = titles[x], x = shakespeare.lines)[2]
}
for (x in 1:n){
  if (x == n){titles.end[x] = length(shakespeare.lines)}
  else {titles.end[x] = titles.start[x+1]-1}
}

titles.start
titles.end
```

Q6. Extracting and analysing a couple of plays
===

- **6a.** Let's look at two of Shakespeare's most famous tragedies. Programmatically find the index at which "THE TRAGEDY OF HAMLET, PRINCE OF DENMARK" occurs in the `titles` vector. Use this to find the indices at which this play starts and ends, in the `titles.start` and `titles.end` vectors, respectively. Call the lines of text corresponding to this play `shakespeare.lines.hamlet`. How many such lines are there? Do the same, but now for the play "THE TRAGEDY OF ROMEO AND JULIET", and call the lines of text corresponding to this play `shakespeare.lines.romeo`. How many such lines are there?

```{r q6a}
hamlet <- titles.start[which(titles == "THE TRAGEDY OF HAMLET, PRINCE OF DENMARK")]
hamlet2 <- titles.end[which(titles == "THE TRAGEDY OF HAMLET, PRINCE OF DENMARK")]
shakespeare.lines.hamlet <- shakespeare.lines[hamlet:hamlet2]
length(shakespeare.lines.hamlet)

romeo <- titles.start[which(titles == "THE TRAGEDY OF ROMEO AND JULIET")]
romeo2 <- titles.end[which(titles == "THE TRAGEDY OF ROMEO AND JULIET")]
shakespeare.lines.romeo <- shakespeare.lines[romeo:romeo2]
length(shakespeare.lines.romeo)
```
**Answer: There are 5259 lines in Hamlet while there are 4093 lines in Romeo**

- **6b.** Repeat the analysis, outlined in Q4, on `shakespeare.lines.hamlet`. (This should mostly just involve copying and pasting code as needed.) That is, to be clear:
      * collapse `shakespeare.lines.hamlet` into one big string, separated by spaces;
      * convert this string into all lower case characters;
      * divide this string into words, by splitting on spaces or on punctuation marks, using `split="[[:space:]]|[[:punct:]]"` in the call to `strsplit()`;
      * remove all empty words (equal to the empty string ""), and report how many words remain;
      * compute the unique words, report the number of unique words, and plot a histogram of their numbers of characters;
      * report the 5 longest words;
      * compute a word table, and report the 25 most common words and their counts;
      * finally, produce a plot of the word counts verus rank.
      
```{r q6b}
temp <- paste(shakespeare.lines.hamlet, collapse = " ")
temp2 <- unlist(strsplit(tolower(temp), split="[[:space:]]|[[:punct:]]"))
shake.hamlet.words <- temp2[temp2 != ""]

length(shake.hamlet.words)
shake.hamlet.words.unique <- unique(shake.hamlet.words)

length(shake.hamlet.words.unique)
hist(nchar(shake.hamlet.words.unique), breaks = 50)
shake.hamlet.words.unique[order(nchar(shake.hamlet.words.unique), 
                                decreasing = TRUE)[1:5]]
shake.hamlet.wordtab <- table(shake.hamlet.words)
shake.hamlet.wordtab.sorted <- sort(shake.hamlet.wordtab, decreasing = TRUE)
head(shake.hamlet.wordtab.sorted,25)

nw = length(shake.hamlet.wordtab.sorted)
plot(1:nw, as.numeric(shake.hamlet.wordtab.sorted), type="l",
     xlab="Rank", ylab="Frequency", xlim = c(1,1000))
```
**Answer: There are 32,977 words in Hamlet, and 4,564 are unique words.**

- **6c.** Repeat the same task as in the last part, but on `shakespeare.lines.romeo`. (Again, this should just involve copying and pasting code as needed. P.S. Isn't this getting tiresome? You'll be happy when we learn more about functions in the near future) Comment on any similarities/differences you see in the answers.

```{r q6c}
temp <- paste(shakespeare.lines.romeo, collapse = " ")
temp2 <- unlist(strsplit(tolower(temp), split="[[:space:]]|[[:punct:]]"))
shake.romeo.words <- temp2[temp2 != ""]

length(shake.romeo.words)
shake.romeo.words.unique <- unique(shake.romeo.words)
length(shake.romeo.words.unique)
hist(nchar(shake.romeo.words.unique), breaks = 50)
shake.romeo.words.unique[order(nchar(shake.romeo.words.unique), 
                               decreasing = TRUE)[1:5]]
shake.romeo.wordtab <- table(shake.romeo.words)
shake.romeo.wordtab.sorted <- sort(shake.romeo.wordtab, decreasing = TRUE)
head(shake.romeo.wordtab.sorted,25)

nw = length(shake.romeo.wordtab.sorted)
plot(1:nw, as.numeric(shake.romeo.wordtab.sorted), type="l",
     xlab="Rank", ylab="Frequency", xlim = c(1,1000))
```
**Romeo and Juliet contains 26,689 words, with 3,571 of them being unique. These counts are lower than those in Hamlet, indicating that Hamlet is likely a longer work. The histograms of word lengths in both plays appear similar, which is expected since they share the same author and likely favor 4-8 character words. In Hamlet, the most frequently occurring word is 'The,' while in Romeo and Juliet, 'and' holds that distinction.**

- **Challenge.** Using a `for()` loop and the `titles.start`, `titles.end` vectors constructed above, answer the following questions. What is Shakespeare's longest play (in terms of the number of words)? What is Shakespeare's shortest play? In which play did Shakespeare use his longest word (in terms of the number of characters)? Are there any plays in which "the" is not the most common word?

```{r q6chal}
longestPlay <- ""
shortestPlay <- ""
longesWordPlay <- ""
longestPlayWordLength <- 0
playsWithoutTheInThem <- character(0)

for (i in 1:length(titles.start)) {
  playTitle <- titles[i]
  playLines <- shakespeare.lines[titles.start[i]:titles.end[i]]
  playText <- paste(playLines, collapse = " ")
  playWords <- unlist(strsplit(tolower(playText), 
                                split = "[[:space:]]|[[:punct:]]"))
  playWords.clean <- playWords[playWords != ""]
  uniqueWords <- unique(playWords.clean)
  
  if (length(playWords.clean) > longestPlayWordLength) {
    longestPlay <- playTitle
    longestPlayWordLength <- length(playWords.clean)
  }
  
  if (shortestPlay == "" || length(playWords.clean) < 
      length(shakespeare.lines[playTitle == shortestPlay])) {
    shortestPlay <- playTitle
  }
  
  longest_word_length <- max(nchar(uniqueWords))
  if (longest_word_length == max(nchar(uniqueWords))) {
    longesWordPlay <- playTitle
  }
  
  if ("the" != uniqueWords[which.max(table(playWords.clean))]) {
    playsWithoutTheInThem <- c(playsWithoutTheInThem, playTitle)
  }
}

longestPlay
shortestPlay
longesWordPlay
playsWithoutTheInThem
```
**Answer: Longest play would be Hamlet, shortest would be Sonnets, and longest character play being Venus and Adnois, couldn't get playsWithoutTheInThem to work right but Sonnets may be the play where The is not the most common word with Venus and Adonis where The is the most common word. I assume this is based off of ranking the amount of times "The" shows up and the longer the play the higher the chances**
